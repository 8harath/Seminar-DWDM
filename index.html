<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Reduction Techniques - Visual Study Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary-blue: #6B2C91;
            --secondary-blue: #00A676;
            --light-blue: #f0e6f6;
            --text-dark: #1a1a1a;
            --text-gray: #4a4a4a;
            --border-gray: #d0d0d0;
            --bg-light: #f8f9fa;
            --highlight-yellow: #fffacd;
            --accent-orange: #FF6B35;
            --metro-purple: #6B2C91;
            --tech-green: #00A676;
            --traffic-orange: #FF6B35;
            --keep-green: #27ae60;
            --remove-red: #e74c3c;
            --warning-yellow: #f39c12;
        }

        body {
            font-family: Georgia, 'Times New Roman', Times, serif;
            background: #ffffff;
            color: var(--text-dark);
            line-height: 1.8;
        }

        .main-container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }

        /* Header - Academic Style */
        header {
            background: var(--primary-blue);
            color: white;
            padding: 40px 60px;
            border-bottom: 4px solid var(--secondary-blue);
        }

        .university-info {
            font-size: 0.9em;
            margin-bottom: 20px;
            opacity: 0.9;
            letter-spacing: 0.5px;
        }

        h1 {
            font-size: 2.5em;
            font-weight: normal;
            margin: 15px 0;
            letter-spacing: 1px;
        }

        .course-info {
            font-size: 1.1em;
            margin-top: 15px;
            opacity: 0.95;
            font-style: italic;
        }

        /* Content Area */
        .content {
            padding: 60px;
        }

        /* Chapter/Section Headers */
        h2 {
            font-size: 1.8em;
            color: var(--primary-blue);
            margin: 40px 0 20px 0;
            padding-bottom: 10px;
            border-bottom: 2px solid var(--primary-blue);
            font-weight: normal;
        }

        h3 {
            font-size: 1.4em;
            color: var(--secondary-blue);
            margin: 30px 0 15px 0;
            font-weight: normal;
        }

        h4 {
            font-size: 1.1em;
            color: var(--text-dark);
            margin: 20px 0 10px 0;
            font-weight: 600;
        }

        /* Paragraph styling */
        p {
            margin: 15px 0;
            text-align: justify;
            color: var(--text-gray);
        }

        /* Definition Box - Textbook Style */
        .definition-box {
            background: var(--light-blue);
            border-left: 5px solid var(--secondary-blue);
            padding: 25px 30px;
            margin: 25px 0;
            font-size: 1.05em;
        }

        .definition-box strong {
            color: var(--primary-blue);
            font-size: 1.1em;
        }

        /* Objective Box */
        .objective-box {
            background: #fff9e6;
            border: 2px solid #ffc107;
            border-left: 5px solid #ffc107;
            padding: 25px 30px;
            margin: 25px 0;
        }

        .objective-box h4 {
            color: #f57c00;
            margin-bottom: 15px;
        }

        .objective-box ul {
            margin-left: 20px;
        }

        .objective-box li {
            margin: 8px 0;
            color: var(--text-gray);
        }

        /* Technique Sections */
        .technique-section {
            margin: 50px 0;
            padding: 30px;
            background: var(--bg-light);
            border: 1px solid var(--border-gray);
        }

        .technique-header {
            background: var(--primary-blue);
            color: white;
            padding: 20px 30px;
            margin: -30px -30px 25px -30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .technique-number {
            background: white;
            color: var(--primary-blue);
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: bold;
        }

        .technique-title {
            font-size: 1.6em;
            font-weight: normal;
        }

        /* Interactive Demo Button - Academic Style */
        .demo-button {
            background: var(--secondary-blue);
            color: white;
            border: none;
            padding: 12px 30px;
            font-size: 1em;
            font-family: Georgia, serif;
            cursor: pointer;
            margin: 20px 0;
            transition: background 0.3s;
        }

        .demo-button:hover {
            background: var(--primary-blue);
        }

        /* Lists */
        ul {
            margin: 15px 0 15px 40px;
        }

        li {
            margin: 10px 0;
            color: var(--text-gray);
        }

        li strong {
            color: var(--text-dark);
        }

        /* Table of Contents */
        .toc {
            background: var(--bg-light);
            border: 2px solid var(--border-gray);
            padding: 30px;
            margin: 30px 0;
        }

        .toc h3 {
            color: var(--primary-blue);
            margin-top: 0;
            border-bottom: 1px solid var(--border-gray);
            padding-bottom: 10px;
        }

        .toc ul {
            list-style: none;
            margin-left: 0;
        }

        .toc li {
            padding: 8px 0;
            border-bottom: 1px dotted var(--border-gray);
        }

        .toc a {
            color: var(--secondary-blue);
            text-decoration: none;
            font-size: 1.05em;
        }

        .toc a:hover {
            text-decoration: underline;
        }

        /* Modal - Academic Paper Style */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.6);
            overflow-y: auto;
        }

        .modal-content {
            background: white;
            margin: 30px auto;
            max-width: 1100px;
            border: 2px solid var(--primary-blue);
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
        }

        .modal-header {
            background: var(--primary-blue);
            color: white;
            padding: 25px 40px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            border-bottom: 3px solid var(--secondary-blue);
        }

        .modal-header h2 {
            color: white;
            border: none;
            margin: 0;
            font-size: 1.8em;
        }

        .close {
            color: white;
            font-size: 35px;
            font-weight: bold;
            cursor: pointer;
            background: rgba(255,255,255,0.2);
            width: 45px;
            height: 45px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 3px;
        }

        .close:hover {
            background: rgba(255,255,255,0.3);
        }

        .modal-body {
            padding: 40px;
        }

        /* Visualization Container */
        .visualization-container {
            background: white;
            border: 2px solid var(--border-gray);
            padding: 30px;
            margin: 25px 0;
        }

        .viz-title {
            color: var(--primary-blue);
            font-size: 1.2em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 1px solid var(--border-gray);
        }

        /* Control Buttons */
        .controls {
            display: flex;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .control-btn {
            background: white;
            color: var(--primary-blue);
            border: 2px solid var(--primary-blue);
            padding: 10px 25px;
            font-size: 1em;
            font-family: Georgia, serif;
            cursor: pointer;
            transition: all 0.3s;
        }

        .control-btn:hover {
            background: var(--primary-blue);
            color: white;
        }

        .control-btn.primary {
            background: var(--secondary-blue);
            color: white;
            border-color: var(--secondary-blue);
        }

        .control-btn.primary:hover {
            background: var(--primary-blue);
            border-color: var(--primary-blue);
        }

        /* Data Table - Academic */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95em;
        }

        .data-table th {
            background: var(--primary-blue);
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: normal;
            border: 1px solid var(--primary-blue);
        }

        .data-table td {
            padding: 10px 12px;
            border: 1px solid var(--border-gray);
            color: var(--text-gray);
        }

        .data-table tr:nth-child(even) {
            background: var(--bg-light);
        }

        .data-table tr:hover {
            background: var(--light-blue);
        }

        /* Charts and Visualizations */
        .bar {
            background: var(--secondary-blue);
            color: white;
            padding: 10px 15px;
            margin: 8px 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: all 0.5s;
            border: 1px solid var(--primary-blue);
        }

        .bar.aggregated {
            background: var(--primary-blue);
        }

        .scatter-plot {
            width: 100%;
            height: 350px;
            border: 2px solid var(--border-gray);
            position: relative;
            background: white;
        }

        .data-point {
            width: 8px;
            height: 8px;
            background: var(--secondary-blue);
            border-radius: 50%;
            position: absolute;
            transition: all 0.5s;
        }

        .data-point.reduced {
            background: var(--primary-blue);
            width: 12px;
            height: 12px;
        }

        /* Progress Bar */
        .progress-bar {
            width: 100%;
            height: 35px;
            background: var(--bg-light);
            border: 1px solid var(--border-gray);
            margin: 20px 0;
        }

        .progress-fill {
            height: 100%;
            background: var(--secondary-blue);
            transition: width 0.5s;
            display: flex;
            align-items: center;
            padding-left: 15px;
            color: white;
            font-weight: normal;
        }

        /* Key Points Box */
        .key-points-box {
            background: white;
            border: 2px solid var(--secondary-blue);
            padding: 25px;
            margin: 25px 0;
        }

        .key-points-box h4 {
            color: var(--primary-blue);
            margin-bottom: 15px;
        }

        .key-points-box ul {
            margin-left: 25px;
        }

        /* Comparison Layout */
        .comparison-layout {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin: 25px 0;
        }

        .comparison-panel {
            border: 2px solid var(--border-gray);
            padding: 20px;
            background: white;
        }

        .comparison-panel h4 {
            color: var(--primary-blue);
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 1px solid var(--border-gray);
        }

        /* Footer */
        footer {
            background: var(--bg-light);
            border-top: 3px solid var(--primary-blue);
            padding: 40px 60px;
            text-align: center;
        }

        footer h3 {
            color: var(--primary-blue);
            margin-bottom: 20px;
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .content {
                padding: 40px;
            }

            .comparison-layout {
                grid-template-columns: 1fr;
            }

            .numerosity-grid {
                grid-template-columns: 1fr;
            }

            #attributeCards {
                grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            }
        }

        @media (max-width: 768px) {
            header, .content, footer {
                padding: 30px;
            }

            h1 {
                font-size: 1.8em;
            }

            .modal-content {
                margin: 20px;
                max-width: 95%;
            }

            .modal-body {
                padding: 25px;
            }

            #attributeCards {
                grid-template-columns: 1fr;
            }

            .controls {
                flex-direction: column;
            }

            .control-btn {
                width: 100%;
            }
        }

        /* Print Styles */
        @media print {
            .demo-button, .control-btn, .close {
                display: none;
            }

            .modal {
                position: relative;
                display: block;
            }
        }

        /* Highlight on hover for learning */
        .data-row {
            transition: background 0.3s;
        }

        .data-row.highlighted {
            background: var(--highlight-yellow) !important;
        }

        .data-row.removing {
            opacity: 0.4;
            text-decoration: line-through;
        }

        .data-row.removed {
            display: none;
        }

        /* Section Numbers */
        .section-number {
            color: var(--secondary-blue);
            font-weight: bold;
            margin-right: 10px;
        }

        /* Animations for Visualizations */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes scaleIn {
            from { opacity: 0; transform: scale(0.8); }
            to { opacity: 1; transform: scale(1); }
        }

        @keyframes growUp {
            from { height: 0; }
            to { height: auto; }
        }

        @keyframes popIn {
            from { opacity: 0; transform: scale(0); }
            to { opacity: 1; transform: scale(1); }
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.2); }
        }

        /* Attribute Cards Grid */
        #attributeCards {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .attribute-card {
            background: white;
            border: 2px solid #ddd;
            border-radius: 8px;
            padding: 20px;
            transition: all 0.5s;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        .attribute-card.irrelevant {
            border-color: #e74c3c;
        }

        /* PCA Containers */
        .pca-container {
            margin: 20px 0;
        }

        /* Numerosity Comparison */
        .numerosity-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <header>
            <div class="university-info">
                JAIN UNIVERSITY<br>
                DEPARTMENT OF COMPUTER SCIENCE & INFORMATION TECHNOLOGY
            </div>
            <h1>Data Reduction Techniques</h1>
            <div class="course-info">
                Module 3: Data Preprocessing | BCA - Data Analytics | 5th Semester
            </div>
            <div id="timer" style="position: absolute; top: 20px; right: 40px; background: white; color: var(--primary-blue); padding: 10px 20px; border: 2px solid var(--primary-blue); font-family: 'Courier New', monospace; font-size: 1.2em; font-weight: bold;">00:00</div>
        </header>

        <div class="content">
            <!-- Abstract/Introduction -->
            <section>
                <h2><span class="section-number">1.</span> Introduction</h2>

                <div class="definition-box">
                    <strong>Definition:</strong> Data reduction obtains a reduced representation of the dataset that is much smaller in volume, yet closely maintains the integrity of the original data. Mining on the reduced data set should be more efficient yet produce the same (or almost the same) analytical results.
                </div>

                <p>
                    In the era of big data, organizations generate and collect massive volumes of data daily. Modern datasets often contain millions to billions of records with hundreds or thousands of attributes. Processing such enormous datasets requires substantial computational resources, time, and storage capacity. Data reduction techniques address these challenges by transforming large datasets into smaller, more manageable representations while preserving the essential information needed for analysis and mining.
                </p>

                <h3>1.1 Motivation for Data Reduction</h3>
                <p>
                    The necessity for data reduction arises from several fundamental challenges in data mining:
                </p>

                <ul>
                    <li><strong>Computational Complexity:</strong> Many data mining algorithms have time complexity that increases exponentially with the size of the dataset or the number of dimensions.</li>
                    <li><strong>Storage Constraints:</strong> Large datasets require significant storage infrastructure, increasing costs and management overhead.</li>
                    <li><strong>The Curse of Dimensionality:</strong> As the number of dimensions increases, the volume of the space increases exponentially, making data sparse and distance measures less meaningful.</li>
                    <li><strong>Visualization Challenges:</strong> High-dimensional data cannot be directly visualized, limiting exploratory data analysis.</li>
                </ul>

                <div class="objective-box">
                    <h4>Learning Objectives</h4>
                    <p>After studying this module, you will be able to:</p>
                    <ul>
                        <li>Understand the fundamental principles of data reduction</li>
                        <li>Identify appropriate reduction techniques for different data types and mining goals</li>
                        <li>Apply five core data reduction strategies with practical examples</li>
                        <li>Evaluate the trade-offs between data reduction and information preservation</li>
                        <li>Implement basic reduction algorithms for real-world datasets</li>
                    </ul>
                </div>
            </section>

            <!-- Table of Contents -->
            <div class="toc">
                <h3>Contents</h3>
                <ul>
                    <li><a href="#section1">1. Introduction to Data Reduction</a></li>
                    <li><a href="#section2">2. Data Cube Aggregation</a></li>
                    <li><a href="#section3">3. Attribute Subset Selection</a></li>
                    <li><a href="#section4">4. Dimensionality Reduction (PCA)</a></li>
                    <li><a href="#section5">5. Numerosity Reduction</a></li>
                    <li><a href="#section6">6. Discretization and Concept Hierarchy</a></li>
                    <li><a href="#summary">Summary and Key Takeaways</a></li>
                </ul>
            </div>

            <!-- Unified Metrics Dashboard -->
            <div style="background: linear-gradient(135deg, var(--metro-purple), var(--tech-green)); padding: 30px; border-radius: 12px; margin: 30px 0; box-shadow: 0 8px 20px rgba(107, 44, 145, 0.2);">
                <h3 style="color: white; text-align: center; margin: 0 0 25px 0; font-size: 1.6em; border: none;">
                    üìä Reduction Metrics Comparison Dashboard
                </h3>
                <div style="background: white; border-radius: 8px; overflow: hidden;">
                    <table class="data-table" id="metricsTable" style="margin: 0;">
                        <thead>
                            <tr>
                                <th>Technique</th>
                                <th>Use Case (Bangalore)</th>
                                <th>Before</th>
                                <th>After</th>
                                <th>Reduction %</th>
                                <th>Info Loss</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Data Cube Aggregation</strong></td>
                                <td>Namma Metro Ridership</td>
                                <td>365 daily records</td>
                                <td>12 monthly records</td>
                                <td style="color: var(--tech-green); font-weight: bold;">96.7%</td>
                                <td style="color: var(--keep-green);">0%* (lossless)</td>
                            </tr>
                            <tr>
                                <td><strong>Feature Selection</strong></td>
                                <td>Apartment Hunting</td>
                                <td>10 features</td>
                                <td>5 features</td>
                                <td style="color: var(--tech-green); font-weight: bold;">50%</td>
                                <td style="color: var(--warning-yellow);">~5%</td>
                            </tr>
                            <tr>
                                <td><strong>PCA (Dimensionality)</strong></td>
                                <td>Restaurant Recommendations</td>
                                <td>10 dimensions</td>
                                <td>2 dimensions</td>
                                <td style="color: var(--tech-green); font-weight: bold;">80%</td>
                                <td style="color: var(--warning-yellow);">~10%</td>
                            </tr>
                            <tr>
                                <td><strong>Sampling</strong></td>
                                <td>ORR Traffic Speed Data</td>
                                <td>100,000 readings</td>
                                <td>1,000 samples</td>
                                <td style="color: var(--tech-green); font-weight: bold;">99%</td>
                                <td style="color: var(--warning-yellow);">~3%</td>
                            </tr>
                            <tr>
                                <td><strong>Discretization</strong></td>
                                <td>Ola/Uber Surge Pricing</td>
                                <td>Continuous demand</td>
                                <td>5 pricing tiers</td>
                                <td style="color: var(--tech-green); font-weight: bold;">N/A</td>
                                <td style="color: var(--traffic-orange);">~15%</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div style="text-align: center; margin-top: 20px; color: white; font-size: 0.9em; opacity: 0.95;">
                    ‚≠ê All use cases based on real Bangalore scenarios for better understanding
                </div>
            </div>

            <!-- Five Techniques -->
            <h2><span class="section-number">2.</span> Five Core Data Reduction Strategies</h2>

            <p>
                Data reduction strategies can be categorized into five primary approaches, each suited to different types of data and analytical objectives. The following sections provide detailed explanations and interactive demonstrations of each technique using real-world Bangalore examples.
            </p>

            <!-- Technique 1: Data Cube Aggregation -->
            <div class="technique-section" id="section2">
                <div class="technique-header">
                    <div class="technique-title">2.1 Data Cube Aggregation</div>
                    <div class="technique-number">1</div>
                </div>

                <h4>Real-World Use Case: Namma Metro Ridership Analysis üöá</h4>
                <p>
                    <strong>Scenario:</strong> Bangalore Metro Rail Corporation (BMRCL) collects ridership data for all stations across the Purple and Green lines. Every day, detailed passenger counts are recorded for each station. Analyzing 365 days of raw data for multiple stations is computationally expensive. Data cube aggregation helps by creating summary views at different time granularities.
                </p>

                <h4>Why This Matters in Bangalore</h4>
                <ul>
                    <li><strong>Peak Hour Planning:</strong> Understanding daily vs monthly patterns helps optimize metro frequency during office rush hours (8-10 AM, 5-8 PM)</li>
                    <li><strong>Seasonal Trends:</strong> Identify reduced ridership during festivals (Dasara, Diwali) when people travel out of Bangalore</li>
                    <li><strong>Infrastructure Planning:</strong> Quarterly aggregates help BMRCL decide where to add new lines or extend existing ones</li>
                    <li><strong>Storage Efficiency:</strong> Instead of storing 365 daily records, store 12 monthly summaries (96.7% reduction)</li>
                </ul>

                <h4>Methodology</h4>
                <p>
                    Common aggregation operations include SUM (total riders), AVERAGE (avg daily riders), COUNT (number of days), MIN/MAX (peak identification). These operations can be applied across different time dimensions: Daily ‚Üí Monthly ‚Üí Quarterly ‚Üí Yearly.
                </p>

                <button class="demo-button" onclick="showDemo('datacube')">
                    ‚ñ∫ View Interactive Demonstration
                </button>

                <div class="key-points-box">
                    <h4>Key Considerations</h4>
                    <ul>
                        <li><strong>Information Loss:</strong> Detail-level information is permanently lost after aggregation</li>
                        <li><strong>Query Performance:</strong> Pre-aggregated data enables significantly faster query responses</li>
                        <li><strong>Storage Trade-off:</strong> Maintaining multiple aggregation levels requires additional storage</li>
                        <li><strong>Typical Reduction:</strong> 10x to 100x reduction in data volume</li>
                    </ul>
                </div>
            </div>

            <!-- Technique 2: Attribute Selection -->
            <div class="technique-section" id="section3">
                <div class="technique-header">
                    <div class="technique-title">2.2 Attribute Subset Selection (Feature Selection)</div>
                    <div class="technique-number">2</div>
                </div>

                <h4>Real-World Use Case: Apartment Hunting in Bangalore üè†</h4>
                <p>
                    <strong>Scenario:</strong> You're searching for an apartment in Bangalore using platforms like 99acres or MagicBricks. The website shows 50+ features for each property, but which ones actually matter for your decision? Feature selection helps identify the most relevant attributes while eliminating noise.
                </p>

                <h4>Why This Matters in Bangalore</h4>
                <ul>
                    <li><strong>Simplify Choices:</strong> Instead of comparing 50 features across 100 apartments, focus on the 5-7 that truly influence your decision</li>
                    <li><strong>Faster Search:</strong> Filtering by only relevant features (Metro proximity, IT park distance) speeds up apartment discovery</li>
                    <li><strong>Better Models:</strong> Property price prediction models work better with relevant features, avoiding overfitting</li>
                    <li><strong>Interpretability:</strong> Easily explain to family: "We chose this based on Metro access, safety, and rent"</li>
                </ul>

                <h4>Feature Examples</h4>
                <p><strong>Highly Relevant:</strong> Distance to Office/Metro (0.85 correlation), Rent Price (0.82), Safety Rating (0.65)</p>
                <p><strong>Irrelevant:</strong> Building Paint Color (0.03), Landlord's Zodiac Sign (0.01), House Number Numerology (0.02)</p>
                <p><strong>Redundant:</strong> Parking Space and Balcony Size (both correlated with Rent)</p>

                <h4>Selection Methods</h4>
                <ul>
                    <li><strong>Correlation Analysis:</strong> Measure relationship between each feature and target (apartment choice)</li>
                    <li><strong>Forward Selection:</strong> Start empty, iteratively add most impactful features (distance to Metro ‚Üí then rent ‚Üí then safety)</li>
                    <li><strong>Backward Elimination:</strong> Start with all 50 features, iteratively remove least useful ones</li>
                </ul>

                <button class="demo-button" onclick="showDemo('attribute')">
                    ‚ñ∫ View Interactive Demonstration
                </button>

                <div class="key-points-box">
                    <h4>Key Considerations</h4>
                    <ul>
                        <li><strong>Threshold Selection:</strong> Typically retain attributes with |correlation| > 0.3</li>
                        <li><strong>Domain Knowledge:</strong> Subject matter expertise crucial for feature selection</li>
                        <li><strong>Interaction Effects:</strong> Some features may be weak individually but strong in combination</li>
                        <li><strong>Typical Reduction:</strong> 50% to 90% reduction in number of features</li>
                    </ul>
                </div>
            </div>

            <!-- Technique 3: PCA -->
            <div class="technique-section" id="section4">
                <div class="technique-header">
                    <div class="technique-title">2.3 Dimensionality Reduction: Principal Component Analysis</div>
                    <div class="technique-number">3</div>
                </div>

                <h4>Real-World Use Case: Restaurant Recommendations (Swiggy/Zomato) üçΩÔ∏è</h4>
                <p>
                    <strong>Scenario:</strong> Food delivery apps analyze hundreds of restaurants in Bangalore using 10+ features: Taste Rating, Price Level, Delivery Speed, Hygiene Score, Ambiance, Parking, Live Music, Outdoor Seating, Distance, Cuisine Type. To visualize restaurant similarity or create recommendation clusters, we need to reduce these 10 dimensions to 2D that can be plotted.
                </p>

                <h4>Why This Matters in Bangalore</h4>
                <ul>
                    <li><strong>Visual Discovery:</strong> Plot all Indiranagar restaurants on a 2D map based on "Overall Quality" vs "Experience vs Quick Service"</li>
                    <li><strong>Smart Recommendations:</strong> "People who liked MTR also liked Vidyarthi Bhavan" - based on similarity in reduced space</li>
                    <li><strong>Trend Analysis:</strong> Identify if Koramangala restaurants prioritize ambiance (PC1) while Whitefield prioritizes delivery speed (PC2)</li>
                    <li><strong>Dimension Reduction:</strong> 10 features ‚Üí 2 principal components retaining 90% of variance (80% reduction)</li>
                </ul>

                <h4>Principal Components Interpretation</h4>
                <p><strong>PC1 (55% variance):</strong> "Overall Quality & Convenience" - combines Taste, Hygiene, Price, Distance</p>
                <p><strong>PC2 (35% variance):</strong> "Experience vs Quick Service" - separates dine-in ambiance from delivery-focused restaurants</p>

                <h4>Mathematical Foundation</h4>
                <p>
                    PCA works by computing the covariance matrix of the normalized data, then finding its eigenvectors and eigenvalues. The eigenvectors with the largest eigenvalues become the principal components, representing the directions of maximum variance.
                </p>

                <h4>Algorithm Steps</h4>
                <ol>
                    <li>Normalize restaurant features (mean = 0, standard deviation = 1)</li>
                    <li>Compute 10√ó10 covariance matrix showing feature relationships</li>
                    <li>Calculate eigenvectors (new composite dimensions) and eigenvalues (variance captured)</li>
                    <li>Sort eigenvectors by eigenvalues (descending) - highest variance first</li>
                    <li>Select top 2 eigenvectors as Principal Components 1 & 2</li>
                    <li>Project all restaurants onto this 2D space for visualization</li>
                </ol>

                <button class="demo-button" onclick="showDemo('pca')">
                    ‚ñ∫ View Interactive Demonstration
                </button>

                <div class="key-points-box">
                    <h4>Key Considerations</h4>
                    <ul>
                        <li><strong>Variance Retention:</strong> Typically retain 85-95% of variance with far fewer dimensions</li>
                        <li><strong>Interpretability Loss:</strong> Principal components are linear combinations, not original features</li>
                        <li><strong>Linearity Assumption:</strong> PCA captures only linear relationships</li>
                        <li><strong>Applications:</strong> Image compression, noise reduction, visualization, preprocessing</li>
                    </ul>
                </div>

                <h4 style="margin-top: 30px;">Wavelet Transforms</h4>
                <p>
                    Wavelet transforms offer an alternative to PCA for dimensionality reduction. Using a hierarchical pyramid algorithm, wavelets decompose signals by repeatedly halving the data, achieving better lossy compression than Discrete Fourier Transforms (DFT). Popular wavelet families include Haar-2, Daubechies-4, and Daubechies-6.
                </p>

                <button class="demo-button" onclick="showDemo('wavelet')">
                    ‚ñ∫ View Wavelet Transform Demonstration
                </button>
            </div>

            <!-- Technique 4: Numerosity Reduction -->
            <div class="technique-section" id="section5">
                <div class="technique-header">
                    <div class="technique-title">2.4 Numerosity Reduction</div>
                    <div class="technique-number">4</div>
                </div>

                <h4>Real-World Use Case: ORR Traffic Speed Analysis üöó</h4>
                <p>
                    <strong>Scenario:</strong> Google Maps/Ola Maps collect vehicle speed readings every 30 seconds on Bangalore's Outer Ring Road (ORR). Over one week, this generates 100,000+ speed measurements. Storing and analyzing all readings is expensive. Numerosity reduction creates smaller, representative datasets.
                </p>

                <h4>Why This Matters in Bangalore</h4>
                <ul>
                    <li><strong>Traffic Prediction:</strong> Use 1,000 sampled readings instead of 100,000 to predict congestion patterns (99% reduction, ~3% accuracy loss)</li>
                    <li><strong>Route Optimization:</strong> Quickly estimate average ORR speed during office hours using histogram bins (Morning: 25 km/h, Afternoon: 45 km/h, Evening: 15 km/h)</li>
                    <li><strong>Trend Modeling:</strong> Fit regression model "Speed = f(Time of Day)" using just 2 parameters instead of 100,000 data points</li>
                    <li><strong>Storage Savings:</strong> Historical traffic data compressed by 90-99% while maintaining useful insights</li>
                </ul>

                <h4>Non-Parametric Methods</h4>
                <ul>
                    <li><strong>Random Sampling (10%):</strong> Select 1,000 random speed readings from 100,000 - maintains distribution, 90% reduction</li>
                    <li><strong>Stratified Sampling:</strong> Sample proportionally from time periods (25% morning rush, 25% afternoon, 25% evening rush, 25% night) - ensures all periods represented</li>
                    <li><strong>Histograms:</strong> Group speeds into bins (0-20 km/h, 21-40 km/h, 41-60 km/h, 61+ km/h) with counts - preserves distribution shape</li>
                </ul>

                <h4>Parametric Methods</h4>
                <ul>
                    <li><strong>Regression Models:</strong> Speed = 50 - 35 √ó sin(hour/24 √ó 2œÄ) - captures daily pattern with just 2 parameters</li>
                    <li><strong>Time Series Models:</strong> ARIMA/SARIMA models storing only coefficients instead of raw readings</li>
                </ul>

                <button class="demo-button" onclick="showDemo('numerosity')">
                    ‚ñ∫ View Interactive Demonstration (Basic)
                </button>

                <h4 style="margin-top: 30px;">Advanced Numerosity Reduction Demonstrations</h4>
                <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 15px; margin: 20px 0;">
                    <button class="demo-button" onclick="showDemo('samplingMethods')" style="margin: 0;">
                        ‚ñ∫ Sampling Methods Comparison
                    </button>
                    <button class="demo-button" onclick="showDemo('histogramTypes')" style="margin: 0;">
                        ‚ñ∫ Histogram Types (Equal-Width/Frequency)
                    </button>
                    <button class="demo-button" onclick="showDemo('regression')" style="margin: 0;">
                        ‚ñ∫ Regression Models
                    </button>
                </div>

                <div class="key-points-box">
                    <h4>Key Considerations</h4>
                    <ul>
                        <li><strong>Sampling Rate:</strong> 10% sample typically sufficient for large datasets</li>
                        <li><strong>Statistical Validity:</strong> Ensure sample maintains population distribution</li>
                        <li><strong>Histogram Bins:</strong> Too few bins lose detail, too many defeat purpose</li>
                        <li><strong>Typical Reduction:</strong> 90-99% reduction in data volume</li>
                    </ul>
                </div>
            </div>

            <!-- Technique 5: Discretization -->
            <div class="technique-section" id="section6">
                <div class="technique-header">
                    <div class="technique-title">2.5 Discretization and Concept Hierarchy Generation</div>
                    <div class="technique-number">5</div>
                </div>

                <h4>Real-World Use Case: Ola/Uber Surge Pricing in Bangalore üöï</h4>
                <p>
                    <strong>Scenario:</strong> Ride-sharing apps monitor continuous demand data (ride requests per minute) in areas like Koramangala, Whitefield, Electronic City. Instead of using raw continuous demand values, they discretize into pricing tiers. This makes dynamic pricing easier to implement and explain to users.
                </p>

                <h4>Why This Matters in Bangalore</h4>
                <ul>
                    <li><strong>Transparent Pricing:</strong> Users understand "‚Çπ1.0√ó (No Surge)", "‚Çπ1.5√ó (Surge)", "‚Çπ2.5√ó (High Demand)" better than continuous multipliers like 1.37√ó or 1.89√ó</li>
                    <li><strong>Quick Decision Rules:</strong> "If requests > 75/min in Koramangala ‚Üí High Demand tier" - faster than complex continuous formulas</li>
                    <li><strong>Pattern Analysis:</strong> Identify "MG Road is in High Demand 18% of the time (6-8 PM)" using discrete time bins</li>
                    <li><strong>Fair Thresholds:</strong> Entropy-based binning creates optimal boundaries that balance revenue with user satisfaction</li>
                </ul>

                <h4>Example: Koramangala Hourly Demand</h4>
                <p><strong>Continuous Data:</strong> 5:00 AM (2 requests), 8:00 AM (87 requests), 6:00 PM (142 requests), 10:00 PM (34 requests)</p>
                <p><strong>Equal-Width Bins:</strong> 0-50 ‚Üí ‚Çπ1.0√ó, 51-100 ‚Üí ‚Çπ1.5√ó, 101-150 ‚Üí ‚Çπ2.0√ó</p>
                <p><strong>Equal-Frequency Bins:</strong> 0-15 ‚Üí ‚Çπ1.0√ó (33% hours), 16-40 ‚Üí ‚Çπ1.5√ó (33%), 41+ ‚Üí ‚Çπ2.0√ó (33%)</p>
                <p><strong>Entropy-Based:</strong> 0-25 ‚Üí ‚Çπ1.0√ó, 26-75 ‚Üí ‚Çπ1.5√ó, 76+ ‚Üí ‚Çπ2.5√ó (optimized for demand classification)</p>

                <h4>Discretization Methods</h4>
                <ul>
                    <li><strong>Equal-Width:</strong> Uniform intervals - simple but sensitive to outliers (e.g., festivals with 300+ requests)</li>
                    <li><strong>Equal-Frequency:</strong> Balanced demand distribution - ensures each tier has similar time coverage</li>
                    <li><strong>Entropy-Based:</strong> Minimizes information loss - finds optimal split points based on actual demand patterns</li>
                </ul>

                <h4>Concept Hierarchies</h4>
                <p>
                    Discretization can be performed at multiple levels: Fine-grained (10 tiers: ‚Çπ1.0√ó, ‚Çπ1.1√ó, ..., ‚Çπ2.0√ó) ‚Üí Medium (5 tiers) ‚Üí Coarse (3 tiers: No Surge, Surge, High Surge). Higher levels useful for reporting, lower levels for precise pricing.
                </p>

                <button class="demo-button" onclick="showDemo('discretization')">
                    ‚ñ∫ View Interactive Demonstration
                </button>

                <div class="key-points-box">
                    <h4>Key Considerations</h4>
                    <ul>
                        <li><strong>Number of Bins:</strong> Balance between granularity and simplicity</li>
                        <li><strong>Domain Knowledge:</strong> Natural breakpoints (e.g., age groups) often preferred</li>
                        <li><strong>Reversibility:</strong> Discretization is lossy, original values cannot be recovered</li>
                        <li><strong>Applications:</strong> Association rule mining, decision trees, data visualization</li>
                    </ul>
                </div>
            </div>

            <!-- Summary Section -->
            <section id="summary">
                <h2><span class="section-number">3.</span> Summary and Guidelines</h2>

                <h3>3.1 Technique Selection Guidelines</h3>
                <p>
                    Selecting the appropriate data reduction technique depends on several factors:
                </p>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Scenario</th>
                            <th>Recommended Technique</th>
                            <th>Rationale</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>High-dimensional dataset (100+ attributes)</td>
                            <td>PCA or Attribute Selection</td>
                            <td>Addresses curse of dimensionality</td>
                        </tr>
                        <tr>
                            <td>Need interpretable results</td>
                            <td>Attribute Selection or Discretization</td>
                            <td>Preserves original features</td>
                        </tr>
                        <tr>
                            <td>Time-series or sequential data</td>
                            <td>Aggregation or Wavelet Transforms</td>
                            <td>Maintains temporal patterns</td>
                        </tr>
                        <tr>
                            <td>Very large dataset (millions of records)</td>
                            <td>Sampling or Clustering</td>
                            <td>Provides representative subset</td>
                        </tr>
                        <tr>
                            <td>Business intelligence dashboards</td>
                            <td>Data Cube Aggregation</td>
                            <td>Enables OLAP operations</td>
                        </tr>
                        <tr>
                            <td>Continuous attributes for rule mining</td>
                            <td>Discretization</td>
                            <td>Enables categorical analysis</td>
                        </tr>
                    </tbody>
                </table>

                <h3>3.2 Key Principles</h3>
                <div class="definition-box">
                    <p>
                        <strong>Fundamental Principle:</strong> The effectiveness of data reduction is measured by the degree to which it reduces data volume while maintaining the integrity needed for the intended analytical task. There is always a trade-off between reduction and information preservation.
                    </p>
                </div>

                <ul>
                    <li><strong>Validate Results:</strong> Always compare mining results on reduced vs. original data</li>
                    <li><strong>Domain Expertise:</strong> Incorporate subject matter knowledge when selecting techniques</li>
                    <li><strong>Combine Techniques:</strong> Multiple reduction methods can be applied sequentially</li>
                    <li><strong>Document Decisions:</strong> Maintain clear records of reduction parameters and rationale</li>
                </ul>

                <h3>3.3 Practical Considerations</h3>
                <p>
                    When implementing data reduction in real-world scenarios, consider the following:
                </p>

                <ul>
                    <li>Start with exploratory data analysis to understand data characteristics</li>
                    <li>Test multiple reduction techniques and compare results</li>
                    <li>Monitor computational savings vs. accuracy trade-offs</li>
                    <li>Update reduction strategies as data evolves over time</li>
                    <li>Consider the end-user's needs for interpretability and granularity</li>
                </ul>
            </section>
        </div>

        <!-- Modals for Interactive Demos -->

        <!-- Data Cube Modal -->
        <div id="datacubeModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Data Cube Aggregation</h2>
                    <span class="close" onclick="closeModal('datacubeModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        This demonstration shows how a full year of detailed daily sales data (365 records) is progressively aggregated into higher-level summaries through multiple levels: monthly, quarterly, and yearly. Observe how the number of data points decreases dramatically while preserving the total sales information at each level.
                    </p>

                    <div class="controls">
                        <button class="control-btn primary" onclick="aggregateDaily()">Step 1: Daily ‚Üí Monthly (365 ‚Üí 12)</button>
                        <button class="control-btn primary" onclick="aggregateMonthly()">Step 2: Monthly ‚Üí Quarterly (12 ‚Üí 4)</button>
                        <button class="control-btn primary" onclick="aggregateQuarterly()">Step 3: Quarterly ‚Üí Yearly (4 ‚Üí 1)</button>
                        <button class="control-btn" onclick="resetDataCube()">Reset to Daily Data</button>
                    </div>

                    <div class="visualization-container">
                        <div class="viz-title">Sales Data Visualization - Progressive Aggregation</div>
                        <div id="datacubeChart"></div>
                    </div>

                    <h4>Observations</h4>
                    <ul>
                        <li><strong>Daily data:</strong> 365 records ‚Üí <strong>Monthly data:</strong> 12 records (96.7% reduction)</li>
                        <li><strong>Monthly data:</strong> 12 records ‚Üí <strong>Quarterly data:</strong> 4 records (98.9% reduction from original)</li>
                        <li><strong>Quarterly data:</strong> 4 records ‚Üí <strong>Yearly data:</strong> 1 record (99.73% total reduction)</li>
                        <li>Total sales value remains constant across all aggregation levels</li>
                        <li>Query performance improves dramatically at each aggregation level</li>
                        <li>Storage requirements reduced from 365 records to just 1 summary record</li>
                    </ul>
                </div>
            </div>
        </div>

        <!-- Attribute Selection Modal -->
        <div id="attributeModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Attribute Selection</h2>
                    <span class="close" onclick="closeModal('attributeModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Attribute Subset Selection (Feature Selection) reduces the dataset size by removing irrelevant, weakly relevant, or redundant attributes. This demonstration shows three different methods for selecting the optimal feature subset.
                    </p>

                    <!-- Method Selection Tabs -->
                    <div style="display: flex; gap: 10px; margin: 20px 0; border-bottom: 2px solid #ddd;">
                        <button onclick="showAttributeMethod('basic')" id="basicTab" style="flex: 1; padding: 12px; background: #003366; color: white; border: none; cursor: pointer; font-weight: bold;">Basic Correlation Analysis</button>
                        <button onclick="showAttributeMethod('forward')" id="forwardTab" style="flex: 1; padding: 12px; background: #e0e0e0; color: #666; border: none; cursor: pointer;">Forward Selection</button>
                        <button onclick="showAttributeMethod('backward')" id="backwardTab" style="flex: 1; padding: 12px; background: #e0e0e0; color: #666; border: none; cursor: pointer;">Backward Elimination</button>
                    </div>

                    <!-- Basic Correlation Analysis -->
                    <div id="basicMethod" style="display: block;">
                        <h4 style="color: #003366;">Method 1: Correlation-Based Selection</h4>
                        <p>Evaluate all features by their correlation with the target variable and remove those below threshold.</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="calculateCorrelation()">Step 1: Analyze Correlations</button>
                            <button class="control-btn primary" onclick="removeIrrelevant()">Step 2: Remove Irrelevant Features</button>
                            <button class="control-btn" onclick="resetAttributes()">Reset Features</button>
                        </div>

                        <div class="visualization-container">
                            <div class="viz-title">Feature Correlation Analysis - Interactive Cards</div>
                            <div id="attributeCards"></div>
                            <div class="progress-bar">
                                <div class="progress-fill" id="attributeProgress" style="width: 0%">0% Removed</div>
                            </div>
                        </div>

                        <h4>Selection Criteria</h4>
                        <ul>
                            <li><strong>High Correlation (|r| ‚â• 0.70):</strong> Strong predictors, definitely retain</li>
                            <li><strong>Moderate Correlation (0.30 ‚â§ |r| < 0.70):</strong> Useful features, consider retaining</li>
                            <li><strong>Low Correlation (|r| < 0.30):</strong> Weak predictors, candidates for removal</li>
                            <li><strong>Zero Correlation (|r| ‚âà 0):</strong> No linear relationship, remove unless domain knowledge suggests otherwise</li>
                        </ul>
                    </div>

                    <!-- Forward Selection Method -->
                    <div id="forwardMethod" style="display: none;">
                        <h4 style="color: #003366;">Method 2: Forward Selection (Greedy Algorithm)</h4>
                        <p><strong>Strategy:</strong> Start with an empty set and iteratively add the best attribute at each step.</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="stepForwardSelection()">‚ñ∂ Add Next Best Attribute</button>
                            <button class="control-btn primary" onclick="autoForwardSelection()">‚è© Auto-Select All (|r| ‚â• 0.30)</button>
                            <button class="control-btn" onclick="resetForwardSelection()">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="forwardSelectionViz"></div>
                        </div>
                    </div>

                    <!-- Backward Elimination Method -->
                    <div id="backwardMethod" style="display: none;">
                        <h4 style="color: #003366;">Method 3: Backward Elimination (Greedy Algorithm)</h4>
                        <p><strong>Strategy:</strong> Start with all attributes and iteratively remove the worst attribute at each step.</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="stepBackwardElimination()">‚ñ∂ Remove Worst Attribute</button>
                            <button class="control-btn primary" onclick="autoBackwardElimination()">‚è© Auto-Remove All (|r| < 0.30)</button>
                            <button class="control-btn" onclick="resetBackwardElimination()">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="backwardEliminationViz"></div>
                        </div>
                    </div>

                    <!-- Comparison Section -->
                    <div style="margin-top: 30px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                        <h4 style="color: #003366;">Method Comparison</h4>
                        <table class="data-table">
                            <thead>
                                <tr>
                                    <th>Method</th>
                                    <th>Starting Point</th>
                                    <th>Strategy</th>
                                    <th>Best For</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Correlation Analysis</td>
                                    <td>All features</td>
                                    <td>Evaluate all, remove weak</td>
                                    <td>Quick filtering</td>
                                </tr>
                                <tr>
                                    <td>Forward Selection</td>
                                    <td>Empty set</td>
                                    <td>Iteratively add best</td>
                                    <td>Finding small optimal set</td>
                                </tr>
                                <tr>
                                    <td>Backward Elimination</td>
                                    <td>All features</td>
                                    <td>Iteratively remove worst</td>
                                    <td>Large feature sets</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- PCA Modal -->
        <div id="pcaModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Principal Component Analysis</h2>
                    <span class="close" onclick="closeModal('pcaModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        This demonstration simulates reducing a 100-dimensional dataset to 2 dimensions using PCA. The algorithm identifies the two directions (principal components) that capture the maximum variance in the data.
                    </p>

                    <div class="controls">
                        <button class="control-btn primary" onclick="generatePCAData()">Step 1: Generate Sample Data (100D)</button>
                        <button class="control-btn primary" onclick="applyPCA()">Step 2: Apply PCA (100D ‚Üí 2D)</button>
                        <button class="control-btn" onclick="resetPCA()">Reset</button>
                    </div>

                    <div class="visualization-container">
                        <div class="viz-title">Dimensionality Reduction: Visual Transformation</div>
                        <div class="comparison-layout">
                            <div class="comparison-panel pca-container">
                                <h4>Before PCA: High-Dimensional Data</h4>
                                <div id="pcaDimensions" style="min-height: 250px;"></div>
                            </div>
                            <div class="comparison-panel pca-container">
                                <h4>After PCA: 2D Projection</h4>
                                <div id="pcaReduced" style="min-height: 250px;"></div>
                                <p style="margin-top: 15px; text-align: center; color: var(--primary-blue); font-weight: bold;">
                                    Variance Retained: <span id="varianceRetained" style="font-size: 1.3em; color: #27ae60;">0%</span>
                                </p>
                            </div>
                        </div>
                    </div>

                    <h4>PCA Process</h4>
                    <ol>
                        <li>Normalize data to zero mean and unit variance</li>
                        <li>Compute covariance matrix (100√ó100 for 100D data)</li>
                        <li>Calculate eigenvectors and eigenvalues of covariance matrix</li>
                        <li>Sort eigenvectors by eigenvalues (descending)</li>
                        <li>Select top k=2 eigenvectors as principal components</li>
                        <li>Project original 100D data onto 2D space defined by these components</li>
                    </ol>

                    <h4>Interpretation</h4>
                    <p>
                        Retaining 90-95% of variance with only 2 dimensions demonstrates PCA's effectiveness. The first principal component captures the direction of maximum variance, the second captures the direction of maximum remaining variance orthogonal to the first.
                    </p>
                </div>
            </div>
        </div>

        <!-- Numerosity Modal -->
        <div id="numerosityModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Numerosity Reduction</h2>
                    <span class="close" onclick="closeModal('numerosityModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        This demonstration compares three non-parametric numerosity reduction methods on a dataset of 1,000 points. Each method creates a smaller representation while preserving statistical properties.
                    </p>

                    <div class="controls">
                        <button class="control-btn primary" onclick="showSampling()">Method 1: Random Sampling (10%)</button>
                        <button class="control-btn primary" onclick="showHistogram()">Method 2: Histogram Binning</button>
                        <button class="control-btn primary" onclick="showClustering()">Method 3: Clustering (50 centroids)</button>
                        <button class="control-btn" onclick="resetNumerosity()">Reset</button>
                    </div>

                    <div class="visualization-container">
                        <div class="viz-title">Data Points Reduction Comparison</div>
                        <div class="numerosity-grid">
                            <div id="numerosityOriginal"></div>
                            <div id="numerosityReduced"></div>
                        </div>
                        <div id="reductionStats"></div>
                    </div>

                    <h4>Method Comparison</h4>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>Method</th>
                                <th>Reduction</th>
                                <th>Advantages</th>
                                <th>Disadvantages</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Random Sampling</td>
                                <td>90%</td>
                                <td>Simple, maintains distribution</td>
                                <td>May miss rare patterns</td>
                            </tr>
                            <tr>
                                <td>Histogram</td>
                                <td>~75-90%</td>
                                <td>Preserves distribution shape</td>
                                <td>Loses individual points</td>
                            </tr>
                            <tr>
                                <td>Clustering</td>
                                <td>95%</td>
                                <td>Identifies natural groups</td>
                                <td>Computationally intensive</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>

        <!-- Discretization Modal -->
        <div id="discretizationModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Discretization</h2>
                    <span class="close" onclick="closeModal('discretizationModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Discretization transforms continuous numerical attributes into discrete intervals or categories. This demonstration shows how different binning methods create different interval boundaries and why method selection matters.
                    </p>

                    <!-- Method Selection Tabs -->
                    <div style="display: flex; gap: 10px; margin: 20px 0; border-bottom: 2px solid #ddd;">
                        <button onclick="showDiscretizationMethod('equalwidth')" id="equalWidthTab" style="flex: 1; padding: 12px; background: #003366; color: white; border: none; cursor: pointer; font-weight: bold;">Equal-Width Binning</button>
                        <button onclick="showDiscretizationMethod('equalfreq')" id="equalFreqTab" style="flex: 1; padding: 12px; background: #e0e0e0; color: #666; border: none; cursor: pointer;">Equal-Frequency Binning</button>
                        <button onclick="showDiscretizationMethod('entropy')" id="entropyTab" style="flex: 1; padding: 12px; background: #e0e0e0; color: #666; border: none; cursor: pointer;">Entropy-Based</button>
                        <button onclick="showDiscretizationMethod('comparison')" id="comparisonTab" style="flex: 1; padding: 12px; background: #e0e0e0; color: #666; border: none; cursor: pointer;">Compare All</button>
                    </div>

                    <!-- Equal-Width Method -->
                    <div id="equalWidthMethod" style="display: block;">
                        <h4 style="color: #003366;">Method 1: Equal-Width (Distance) Binning</h4>
                        <p><strong>Strategy:</strong> Divide the range (max - min) into N intervals of equal width</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="stepEqualWidth()">‚ñ∂ Apply Equal-Width Binning</button>
                            <button class="control-btn" onclick="resetDiscretizationMethod('equalwidth')">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="equalWidthViz"></div>
                        </div>

                        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                            <h4 style="color: #003366;">How It Works:</h4>
                            <ol style="color: #666; line-height: 1.8;">
                                <li>Find <strong>min</strong> and <strong>max</strong> values in the data</li>
                                <li>Calculate <strong>range</strong> = max - min</li>
                                <li>Calculate <strong>bin width</strong> = range / N (where N = number of bins)</li>
                                <li>Create N bins: [min, min+width), [min+width, min+2*width), ...</li>
                                <li>Assign each value to its corresponding bin</li>
                            </ol>
                            <div style="margin-top: 15px; padding: 10px; background: white; border-left: 4px solid #3498db; border-radius: 4px;">
                                <strong>‚ö† Limitation:</strong> Can create unbalanced bins if data is skewed or has outliers
                            </div>
                        </div>
                    </div>

                    <!-- Equal-Frequency Method -->
                    <div id="equalFreqMethod" style="display: none;">
                        <h4 style="color: #003366;">Method 2: Equal-Frequency (Depth) Binning</h4>
                        <p><strong>Strategy:</strong> Create bins containing approximately the same number of values</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="stepEqualFreq()">‚ñ∂ Apply Equal-Frequency Binning</button>
                            <button class="control-btn" onclick="resetDiscretizationMethod('equalfreq')">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="equalFreqViz"></div>
                        </div>

                        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                            <h4 style="color: #003366;">How It Works:</h4>
                            <ol style="color: #666; line-height: 1.8;">
                                <li><strong>Sort</strong> all values in ascending order</li>
                                <li>Calculate <strong>bin size</strong> = total values / N</li>
                                <li>Assign first 'bin size' values to Bin 1</li>
                                <li>Assign next 'bin size' values to Bin 2</li>
                                <li>Continue until all values are assigned</li>
                            </ol>
                            <div style="margin-top: 15px; padding: 10px; background: white; border-left: 4px solid #27ae60; border-radius: 4px;">
                                <strong>‚úì Advantage:</strong> Handles skewed distributions well by ensuring balanced bins
                            </div>
                        </div>
                    </div>

                    <!-- Entropy-Based Method -->
                    <div id="entropyMethod" style="display: none;">
                        <h4 style="color: #003366;">Method 3: Entropy-Based Discretization</h4>
                        <p><strong>Strategy:</strong> Use class labels to find optimal split points that minimize entropy</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="stepEntropy()">‚ñ∂ Apply Entropy-Based Binning</button>
                            <button class="control-btn" onclick="resetDiscretizationMethod('entropy')">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="entropyViz"></div>
                        </div>

                        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                            <h4 style="color: #003366;">How It Works:</h4>
                            <ol style="color: #666; line-height: 1.8;">
                                <li>Consider <strong>class labels</strong> (target variable) for each value</li>
                                <li>Calculate <strong>entropy</strong> for each possible split point</li>
                                <li>Choose split points that <strong>maximize information gain</strong></li>
                                <li>Recursively split until stopping criterion met</li>
                                <li>Results in bins with <strong>low entropy</strong> (high class purity)</li>
                            </ol>
                            <div style="margin-top: 15px; padding: 10px; background: white; border-left: 4px solid #9b59b6; border-radius: 4px;">
                                <strong>‚úì Best For:</strong> Classification tasks where class labels are available
                            </div>
                        </div>
                    </div>

                    <!-- Comparison View -->
                    <div id="comparisonMethod" style="display: none;">
                        <h4 style="color: #003366;">Side-by-Side Method Comparison</h4>
                        <p>Compare how different methods bin the same continuous data</p>

                        <div class="controls">
                            <button class="control-btn primary" onclick="compareAllMethods()">‚ñ∂ Generate Comparison</button>
                            <button class="control-btn" onclick="resetDiscretizationMethod('comparison')">‚Üª Reset</button>
                        </div>

                        <div class="visualization-container">
                            <div id="comparisonViz"></div>
                        </div>

                        <div style="margin-top: 20px; padding: 20px; background: #f8f9fa; border-radius: 8px;">
                            <h4 style="color: #003366;">Method Comparison Summary</h4>
                            <table class="data-table">
                                <thead>
                                    <tr>
                                        <th>Method</th>
                                        <th>Bin Creation</th>
                                        <th>Best Use Case</th>
                                        <th>Weakness</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td>Equal-Width</td>
                                        <td>Uniform interval width</td>
                                        <td>Uniformly distributed data</td>
                                        <td>Sensitive to outliers</td>
                                    </tr>
                                    <tr>
                                        <td>Equal-Frequency</td>
                                        <td>Uniform bin counts</td>
                                        <td>Skewed distributions</td>
                                        <td>Bins may span large ranges</td>
                                    </tr>
                                    <tr>
                                        <td>Entropy-Based</td>
                                        <td>Information gain optimization</td>
                                        <td>Classification with labels</td>
                                        <td>Requires class information</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>

                    <!-- Concept Hierarchy Section -->
                    <div style="margin-top: 30px; background: var(--bg-light); padding: 25px; border: 2px solid var(--border-gray); border-radius: 8px;">
                        <h4 style="color: #003366; margin-bottom: 15px;">Concept Hierarchy Generation</h4>
                        <p style="color: #666; margin-bottom: 15px;">Discretization can be performed recursively to create multi-level hierarchies:</p>
                        <div style="text-align: center;">
                            <div style="padding: 15px; background: white; border: 2px solid var(--border-gray); margin: 10px 0;">
                                <strong>Level 0 (Most Detailed):</strong> Individual ages (18, 19, 20, ..., 70, 71)
                            </div>
                            <div style="font-size: 24px; color: var(--primary-blue);">‚Üì</div>
                            <div style="padding: 15px; background: var(--light-blue); border: 2px solid var(--secondary-blue); margin: 10px 0;">
                                <strong>Level 1 (Intermediate):</strong> Youth (18-25) | Adult (26-60) | Senior (61+)
                            </div>
                            <div style="font-size: 24px; color: var(--primary-blue);">‚Üì</div>
                            <div style="padding: 15px; background: var(--primary-blue); color: white; margin: 10px 0;">
                                <strong>Level 2 (Most General):</strong> Young (18-40) | Old (41+)
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Wavelet Transform Modal -->
        <div id="waveletModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Wavelet Transforms</h2>
                    <span class="close" onclick="closeModal('waveletModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Wavelet transforms compress data by hierarchically decomposing signals. The Haar wavelet method (shown here) reduces data size by 50% at each level while preserving the overall signal structure. This is a lossy compression technique.
                    </p>

                    <div class="controls">
                        <button class="control-btn primary" onclick="applyHaarWavelet()">Apply Haar Wavelet Decomposition</button>
                        <button class="control-btn" onclick="resetWavelet()">Reset to Original</button>
                    </div>

                    <div class="visualization-container">
                        <div class="viz-title">Hierarchical Data Compression</div>
                        <div id="waveletViz"></div>
                    </div>

                    <h4>Wavelet Transform Process</h4>
                    <ul>
                        <li><strong>Level 0 (Original):</strong> 32 data points</li>
                        <li><strong>Level 1:</strong> Average pairs ‚Üí 16 coefficients (50% reduction)</li>
                        <li><strong>Level 2:</strong> Average pairs ‚Üí 8 coefficients (75% reduction)</li>
                        <li><strong>Level 3:</strong> Average pairs ‚Üí 4 coefficients (87.5% reduction)</li>
                        <li><strong>Level 4:</strong> Average pairs ‚Üí 2 coefficients (93.75% reduction)</li>
                    </ul>

                    <div class="key-points-box">
                        <h4>Advantages of Wavelet Transforms</h4>
                        <ul>
                            <li>Better compression than Discrete Fourier Transform (DFT)</li>
                            <li>Preserves local detail while reducing storage</li>
                            <li>Popular families: Haar-2, Daubechies-4, Daubechies-6</li>
                            <li>Used in JPEG 2000 image compression, signal processing</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Enhanced Sampling Methods Modal -->
        <div id="samplingMethodsModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Sampling Methods Comparison</h2>
                    <span class="close" onclick="closeModal('samplingMethodsModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Sampling is a numerosity reduction technique that creates a representative subset of data. Different sampling methods have different characteristics and are suitable for different scenarios.
                    </p>

                    <div class="controls">
                        <button class="control-btn primary" onclick="applySRSWOR()">SRSWOR</button>
                        <button class="control-btn primary" onclick="applySRSWR()">SRSWR</button>
                        <button class="control-btn primary" onclick="applyStratified()">Stratified Sample</button>
                        <button class="control-btn primary" onclick="applyCluster()">Cluster Sample</button>
                        <button class="control-btn" onclick="resetSamplingMethods()">Reset</button>
                    </div>

                    <div class="visualization-container">
                        <div class="viz-title">Sampling Methods Demonstration</div>
                        <div class="numerosity-grid">
                            <div id="samplingPopulation"></div>
                            <div id="samplingResult"></div>
                        </div>
                    </div>

                    <h4>Sampling Method Details</h4>
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>Method</th>
                                <th>Description</th>
                                <th>Advantage</th>
                                <th>Best Use Case</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>SRSWOR</td>
                                <td>Simple Random Sample Without Replacement</td>
                                <td>Unbiased, each item selected once</td>
                                <td>General purpose sampling</td>
                            </tr>
                            <tr>
                                <td>SRSWR</td>
                                <td>Simple Random Sample With Replacement</td>
                                <td>Allows bootstrap methods</td>
                                <td>Statistical estimation</td>
                            </tr>
                            <tr>
                                <td>Stratified</td>
                                <td>Sample proportionally from subgroups</td>
                                <td>Ensures representation</td>
                                <td>Skewed or heterogeneous data</td>
                            </tr>
                            <tr>
                                <td>Cluster</td>
                                <td>Select entire groups (e.g., database pages)</td>
                                <td>More efficient I/O</td>
                                <td>Large distributed databases</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="key-points-box">
                        <h4>Key Sampling Principles</h4>
                        <ul>
                            <li>Typically 10% sample is sufficient for large datasets (N > 10,000)</li>
                            <li>Sample must maintain population distribution characteristics</li>
                            <li>Stratified sampling best for ensuring representation of all groups</li>
                            <li>Cluster sampling efficient for large databases stored on multiple pages</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Histogram Types Modal -->
        <div id="histogramTypesModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Histogram Types</h2>
                    <span class="close" onclick="closeModal('histogramTypesModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Histograms partition data into bins, replacing many individual values with summary statistics. This is a popular form of numerosity reduction that maintains data distribution characteristics.
                    </p>

                    <div class="visualization-container">
                        <div class="viz-title">Histogram Types Comparison</div>
                        <div id="histogramComparison"></div>
                    </div>

                    <h4>Histogram Partitioning Rules</h4>
                    <ul>
                        <li><strong>Equal-Width (Distance):</strong> Divide range into N intervals of uniform width. Simple but can have empty bins or outlier-dominated bins.</li>
                        <li><strong>Equal-Frequency (Depth):</strong> Each bin contains approximately same number of values. Better for skewed distributions.</li>
                        <li><strong>V-Optimal:</strong> Minimize variance across all buckets. Computationally intensive but optimal.</li>
                        <li><strong>MaxDiff:</strong> Place boundaries at the Œ≤-1 largest differences between consecutive values.</li>
                    </ul>

                    <div class="key-points-box">
                        <h4>Histogram Best Practices</h4>
                        <ul>
                            <li>Typical number of bins: ‚àöN or log‚ÇÇ(N), where N is number of values</li>
                            <li>Too few bins lose detail; too many bins defeat reduction purpose</li>
                            <li>Equal-frequency often works best for skewed data distributions</li>
                            <li>Histograms maintain approximate data distribution for mining</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>

        <!-- Regression Modal -->
        <div id="regressionModal" class="modal">
            <div class="modal-content">
                <div class="modal-header">
                    <h2>Interactive Demonstration: Regression for Data Reduction</h2>
                    <span class="close" onclick="closeModal('regressionModal')">&times;</span>
                </div>
                <div class="modal-body">
                    <h3>Concept Illustration</h3>
                    <p>
                        Regression is a parametric method for numerosity reduction. Instead of storing all data points, we store only the model parameters (slope and intercept for linear regression). This provides massive data reduction with predictable accuracy.
                    </p>

                    <div class="visualization-container">
                        <div class="viz-title">Linear Regression Model</div>
                        <div id="regressionViz"></div>
                    </div>

                    <h4>Parametric Methods for Numerosity Reduction</h4>
                    <ul>
                        <li><strong>Linear Regression:</strong> y = mx + b (2 parameters)</li>
                        <li><strong>Multiple Linear Regression:</strong> y = b‚ÇÄ + b‚ÇÅx‚ÇÅ + b‚ÇÇx‚ÇÇ + ... (k+1 parameters for k predictors)</li>
                        <li><strong>Polynomial Regression:</strong> y = b‚ÇÄ + b‚ÇÅx + b‚ÇÇx¬≤ + ... (degree+1 parameters)</li>
                        <li><strong>Log-Linear Models:</strong> For discrete multidimensional probability distributions</li>
                    </ul>

                    <div class="key-points-box">
                        <h4>Advantages of Parametric Methods</h4>
                        <ul>
                            <li><strong>Extreme compression:</strong> Thousands of points ‚Üí Few parameters</li>
                            <li><strong>Smoothing effect:</strong> Reduces noise in data</li>
                            <li><strong>Predictive power:</strong> Can estimate values not in original dataset</li>
                            <li><strong>Storage efficiency:</strong> Store only model parameters, not actual data</li>
                        </ul>
                    </div>

                    <h4>Trade-offs</h4>
                    <p style="color: var(--text-gray); padding: 15px; background: var(--bg-light); border-radius: 4px;">
                        Parametric methods work best when data follows the assumed model (e.g., linear relationship).
                        For complex non-linear patterns, non-parametric methods (sampling, clustering, histograms) may be more appropriate.
                        Always validate model accuracy against held-out test data.
                    </p>
                </div>
            </div>
        </div>

        <footer>
            <h3>References and Further Reading</h3>
            <p style="margin: 15px 0; color: var(--text-gray);">
                Han, J., Kamber, M., & Pei, J. (2011). <em>Data Mining: Concepts and Techniques</em> (3rd ed.). Morgan Kaufmann.<br>
                Jolliffe, I. T. (2002). <em>Principal Component Analysis</em> (2nd ed.). Springer.<br>
                Liu, H., & Motoda, H. (2007). <em>Computational Methods of Feature Selection</em>. Chapman & Hall/CRC.
            </p>

            <div style="margin-top: 30px; padding-top: 20px; border-top: 2px solid var(--border-gray);">
                <p style="color: var(--text-gray); font-size: 0.95em;">
                    <strong>Course:</strong> Data Warehousing and Data Mining (23BCA5C01 / 23BCA5D01)<br>
                    <strong>Module:</strong> 3 - Data Preprocessing<br>
                    <strong>Institution:</strong> JAIN University, Department of Computer Science & IT<br>
                    <strong>Academic Year:</strong> 2025-2026 (Odd Semester)
                </p>
            </div>
        </footer>
    </div>

    <script src="visualizations.js"></script>
</body>
</html>
